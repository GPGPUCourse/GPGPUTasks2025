# Теоретическое задание: параллелизуемость/code divergence/memory coalesced access

**1)** Пусть на вход дан сигнал x[n], а на выход нужно дать два сигнала y1[n] и y2[n]:

```
 y1[n] = x[n - 1] + x[n] + x[n + 1]
 y2[n] = y2[n - 2] + y2[n - 1] + x[n]
```

Какой из двух сигналов будет проще и быстрее реализовать в модели массового параллелизма на GPU и почему?

**Ответ:** Проще и быстрее реализовать y1[n]. Каждый y1[n] зависит только от трёх соседних значений x[n−1], x[n], x[n+1], т.е. все n считаются независимо и параллельно, с хорошей локальностью и coalesced-доступом. y2[n] рекуррентен по n (зависит от y2[n−1], y2[n−2]), что создаёт последовательные зависимости; для распараллеливания нужен префикс-скан/разбиение на блоки и синхронизации, что сложнее и медленнее в парадигме массового параллелизма на GPU.

**2)** Предположим что размер warp/wavefront равен 32 и рабочая группа делится
на warp/wavefront-ы таким образом что внутри warp/wavefront
номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Напоминание: инструкция исполняется (пусть и отмаскированно) в каждом потоке warp/wavefront если хотя бы один поток выполняет эту инструкцию неотмаскированно. Если не все потоки выполняют эту инструкцию неотмаскированно - происходит т.н. code divergence.

Пусть размер рабочей группы (32, 32, 1)

```
int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);
if (idx % 32 < 16)
    foo();
else
    bar();
```

Произойдет ли code divergence? Почему?

**Ответ:** Code divergence не будет. Внутри одного warp меняется только `get_local_id(0)` (ось x), а `get_local_id(1)` (ось y) фиксирован для всех 32 потоков этого warp. При размере группы (32, 32, 1) имеем get_local_size(1) = 32, значит `idx = get_local_id(1) + 32 * get_local_id(0)` и потому `idx % 32 = get_local_id(1)`. Следовательно, условие `if (idx % 32 < 16)` эквивалентно проверке `get_local_id(1) < 16`, то есть одно и то же для всех потоков warp.
Значит весь warp целиком идет либо в foo(), либо в bar(), а это означает отсутствие code divergence. Разные warp-ы могут выбрать разные ветви, но divergence определяется внутри warp, а не между ними.

**3)** Как и в прошлом задании предположим что размер warp/wavefront равен 32 и рабочая группа делится
на warp/wavefront-ы таким образом что внутри warp/wavefront
номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Пусть размер рабочей группы (32, 32, 1).
Пусть data - указатель на массив float-данных в глобальной видеопамяти идеально выравненный (выравнен по 128 байтам, т.е. data % 128 == 0). И пусть размер кеш линии - 128 байт.

(a)
```
data[get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

(b)
```
data[get_local_id(1) + get_local_size(1) * get_local_id(0)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

(c)
```
data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** Пусть float = 4 байта, линия кеша 128 байт, размер warp = 32 потока.
(a) `data[get_local_id(0) + get_local_size(0) * get_local_id(1)]`

- Coalesced: да, полностью. Внутри warp y фиксирован, `x` идёт подряд -> 32 последовательных float = 4 * 32 = 128 байт, выровненных.
- Кеш-линии на warp: 1. На рабочую группу (32x32, т.е. 32 warp): 32.

(b) `data[get_local_id(1) + get_local_size(1) * get_local_id(0)]`

- Coalesced: нет. Внутри warp адреса идут с шагом 32 float (=128 байт), каждый поток попадает в свою линию.
- Кеш-линии на warp: 32. На рабочую группу: 32 × 32 = 1024.

(c) `data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)]`

- Coalesced: частично; доступ последовательный, но смещён на 1 float, поэтому не выровнен.
- Кеш-линии на warp: 2 (последовательные 128 байт пересекают границу линии). На рабочую группу: 32 × 2 = 64.

